{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84894,"databundleVersionId":9709193,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code]\n# %% [code]\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-19T15:49:00.192504Z\",\"iopub.execute_input\":\"2024-10-19T15:49:00.193148Z\",\"iopub.status.idle\":\"2024-10-19T15:49:00.210645Z\",\"shell.execute_reply.started\":\"2024-10-19T15:49:00.193078Z\",\"shell.execute_reply\":\"2024-10-19T15:49:00.208900Z\"}}\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-19T15:49:00.213458Z\",\"iopub.execute_input\":\"2024-10-19T15:49:00.213977Z\",\"iopub.status.idle\":\"2024-10-19T15:49:00.223907Z\",\"shell.execute_reply.started\":\"2024-10-19T15:49:00.213930Z\",\"shell.execute_reply\":\"2024-10-19T15:49:00.222109Z\"}}\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-19T15:49:00.228863Z\",\"iopub.execute_input\":\"2024-10-19T15:49:00.229346Z\",\"iopub.status.idle\":\"2024-10-19T15:49:00.441416Z\",\"shell.execute_reply.started\":\"2024-10-19T15:49:00.229301Z\",\"shell.execute_reply\":\"2024-10-19T15:49:00.439842Z\"}}\ntrain_data = pd.read_csv(\"/kaggle/input/playground-series-s4e10/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/playground-series-s4e10/test.csv\")\nsample_sub = pd.read_csv(\"/kaggle/input/playground-series-s4e10/sample_submission.csv\")\n\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Define categorical and numerical features\ncategorical_features = ['person_home_ownership', 'loan_intent', 'loan_grade']\nnumerical_features = ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length']\n\n# Prepare features (X) and target (y) from train data\nX = train_data.drop(columns=['loan_status'])\ny = train_data['loan_status']\n\n# Split train data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define a function to create a model pipeline\ndef create_model_pipeline(model):\n    return Pipeline(steps=[\n        ('preprocessor', ColumnTransformer(\n            transformers=[\n                ('num', 'passthrough', numerical_features),\n                ('cat', OneHotEncoder(), categorical_features)\n            ])),\n        ('model', model)\n    ])\n\n# Initialize Stratified K-Folds\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Hyperparameter tuning for XGBoost\nparam_grid_xgb = {\n    'model__n_estimators': [100, 200],\n    'model__max_depth': [3, 5, 7],\n    'model__learning_rate': [0.01, 0.1, 0.2]\n}\nxgb_pipeline = create_model_pipeline(XGBClassifier(use_label_encoder=False, eval_metric='auc', random_state=42))\ngrid_search_xgb = GridSearchCV(xgb_pipeline, param_grid=param_grid_xgb, cv=kf, scoring='roc_auc', verbose=1, n_jobs=-1)\ngrid_search_xgb.fit(X_train, y_train)\nbest_xgb = grid_search_xgb.best_estimator_\nprint(\"Best XGBoost parameters:\", grid_search_xgb.best_params_)\n\n# Hyperparameter tuning for LightGBM\nparam_grid_lgbm = {\n    'model__n_estimators': [100, 200],\n    'model__max_depth': [-1, 5, 10],\n    'model__num_leaves': [15, 31, 63]  # Add num_leaves parameter to ensure 2^max_depth <= num_leaves\n}\n\nlgbm_pipeline = create_model_pipeline(LGBMClassifier(random_state=42))\ngrid_search_lgbm = GridSearchCV(lgbm_pipeline, param_grid=param_grid_lgbm, cv=kf, scoring='roc_auc', verbose=1, n_jobs=-1)\ngrid_search_lgbm.fit(X_train, y_train)\nbest_lgbm = grid_search_lgbm.best_estimator_\nprint(\"Best LightGBM parameters:\", grid_search_lgbm.best_params_)\n\n# Hyperparameter tuning for Random Forest\nparam_grid_rf = {\n    'model__n_estimators': [100, 200],\n    'model__max_depth': [None, 5, 10],\n    'model__min_samples_split': [2, 5]\n}\nrf_pipeline = create_model_pipeline(RandomForestClassifier(random_state=42))\ngrid_search_rf = GridSearchCV(rf_pipeline, param_grid=param_grid_rf, cv=kf, scoring='roc_auc', verbose=1, n_jobs=-1)\ngrid_search_rf.fit(X_train, y_train)\nbest_rf = grid_search_rf.best_estimator_\nprint(\"Best Random Forest parameters:\", grid_search_rf.best_params_)\n\n# Stacking Classifier\nstacking_model = StackingClassifier(\n    estimators=[\n        ('xgb', best_xgb),\n        ('lgbm', best_lgbm),\n        ('rf', best_rf)\n    ],\n    final_estimator=LogisticRegression(),\n    cv=kf\n)\n\n# Fit stacking model\nstacking_model.fit(X_train, y_train)\n\n# OOF predictions for the validation set\noof_preds = stacking_model.predict_proba(X_val)[:, 1]\nprint(\"Out-of-Fold AUC: \", roc_auc_score(y_val, oof_preds))\n\n# Test predictions\ntest_preds = stacking_model.predict_proba(test_data)[:, 1]\n\n# Prepare submission file\nsubmission = pd.DataFrame({'id': test_data['id'], 'loan_status': test_preds})\nsubmission.to_csv('submission.csv', index=False)\n\nprint(\"Submission file created successfully.\")\n\n","metadata":{"_uuid":"0e33b72b-a393-453a-8a97-1c8f90a79db7","_cell_guid":"d6726400-2ab3-41b7-bcd6-c3b21af1ca21","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}